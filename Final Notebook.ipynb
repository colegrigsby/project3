{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.contrib.learn.python.learn.datasets import base\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.framework import random_seed\n",
    "import time\n",
    "from PIL import Image\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN = '/data/face_dataset/train/'\n",
    "TEST = '/data/face_dataset/test/'\n",
    "def read_images(direc, test=False):\n",
    "\n",
    "    pids = os.listdir(direc)\n",
    "    images = [] \n",
    "    labels = []\n",
    "    for pid in pids:\n",
    "        if test: \n",
    "            labels.append(pid.split('-')[0]) #TODO PID is a filename here \n",
    "            images.append(direc + pid)\n",
    "        else: \n",
    "            for image_file in os.listdir(direc + pid):\n",
    "                #imagefiles.append(image_file)\n",
    "                labels.append(int(pid))\n",
    "                images.append(direc + pid + '/' + image_file)\n",
    "\n",
    "    #print(images)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "train_images, train_labels = read_images(TRAIN)\n",
    "test_images, test_labels = read_images(TEST, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_order = train_labels.copy()\n",
    "label_order = set(label_order)\n",
    "label_order = sorted(list(label_order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def writeTfrecords(toname, filenames, labels, train=True, shuf=True):\n",
    "    def _bytes_feature(value):\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "    def _int64_feature(value):\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "    \n",
    "    def _float32_feature(value):\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "    tfrecords_filename = toname\n",
    "\n",
    "    writer = tf.python_io.TFRecordWriter(tfrecords_filename)\n",
    "\n",
    "    c = list(zip(filenames, labels))\n",
    "    if shuf: \n",
    "        shuffle(c)\n",
    "    \n",
    "    for img_path, label in c:\n",
    "\n",
    "        img = np.array(Image.open(img_path))\n",
    "                \n",
    "        y_arr = np.zeros([398])\n",
    "        if train:\n",
    "            ind = label_order.index(label)\n",
    "            #print(ind)\n",
    "            y_arr[ind] = 1\n",
    "        \n",
    "        \n",
    "        #print(y_arr.reshape(-1))\n",
    "\n",
    "        img_raw = img.tostring()\n",
    "\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'image_raw': _bytes_feature(img_raw),\n",
    "            'labels_raw': _float32_feature(y_arr.reshape(-1))}))\n",
    "\n",
    "        writer.write(example.SerializeToString())\n",
    "\n",
    "    writer.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# writeTfrecords(\"traindataset2.tfrecords\", train_images, train_labels, shuf=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# writeTfrecords(\"testdataset2.tfrecords\", test_images, test_labels, train=False, shuf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_tfrecords(example_proto):\n",
    "    \n",
    "    features = tf.parse_single_example(\n",
    "      example_proto,\n",
    "      # Defaults are not specified since both keys are required.\n",
    "      features={\n",
    "        'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "        'labels_raw': tf.FixedLenFeature([398], tf.float32)\n",
    "        })\n",
    "    \n",
    "    image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    image = tf.reshape(image, [64 * 64, 3])\n",
    "    #print(image.shape)\n",
    "        \n",
    "    return image, features[\"labels_raw\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 64 * 64, 3])\n",
    "W = tf.Variable(tf.zeros([64 * 64, 3, 398]))\n",
    "b = tf.Variable(tf.zeros([398]))\n",
    "y_ = tf.placeholder(tf.float32, [None, 398])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape, value):\n",
    "    initial = tf.constant(value, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 3, 32])\n",
    "b_conv1 = bias_variable([32], 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1,64,64,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64], 1.0)\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([16 * 16 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024], 1.0)\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 16*16*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO \n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob) #don't start with this, its hard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024, 398])\n",
    "b_fc2 = bias_variable([398], 1.0)\n",
    "\n",
    "y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "#y_conv=tf.nn.softmax(tf.matmul(h_fc1, W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "traindata = tf.data.TFRecordDataset(['traindataset2.tfrecords'])\n",
    "traindata = traindata.map(parse_tfrecords)\n",
    "traindata = traindata.batch(BATCH_SIZE)\n",
    "\n",
    "testdata = tf.data.TFRecordDataset(['testdataset2.tfrecords'])\n",
    "testdata = testdata.map(parse_tfrecords)\n",
    "testdata = testdata.batch(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.maximum(y_conv + 1e-10, 1.0)), reduction_indices=[1]))\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.clip_by_value(y_conv, 1e-10, 1.0)), reduction_indices=[1]))\n",
    "\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "itera = traindata.make_initializable_iterator()\n",
    "next_element = itera.get_next()\n",
    "\n",
    "itertest = testdata.make_initializable_iterator()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "#     for i in range(100):\n",
    "    for i in range(100):\n",
    "        sess.run(itera.initializer)\n",
    "        its = 0 \n",
    "        start_time = time.time()\n",
    "        \n",
    "        print(\"starting epoch \" + str(i))\n",
    "#         while True:\n",
    "#             try:\n",
    "#                 t = sess.run(next_element)\n",
    "#                 #print(t[0])\n",
    "#                 #print(sess.run(tf.argmax(y_conv, 1), feed_dict={x: t[0], keep_prob:1.0}))\n",
    "                \n",
    "#                 if its % 100 == 0:\n",
    "#                     train_accuracy = accuracy.eval(feed_dict={\n",
    "#                         x:t[0], y_: t[1], keep_prob:1.0})\n",
    "#                     print(\"step %d, training accuracy %f\" % (its, train_accuracy))\n",
    "                    \n",
    "                    \n",
    "#                 train_step.run(feed_dict={x: t[0],  y_: t[1], keep_prob:0.5})\n",
    "\n",
    "#                 its += 1\n",
    "#             except tf.errors.OutOfRangeError:\n",
    "#                 break\n",
    "                \n",
    "        print(\"testing and saving\")\n",
    "        saver.save(sess, '/home/colegrigsby/proj3/model' + str(i))\n",
    "        predictions = []\n",
    "        sess.run(itertest.initializer)\n",
    "        while True:\n",
    "            try: \n",
    "                tt = sess.run(itertest.get_next())\n",
    "                p = sess.run(tf.argmax(y_conv, 1), feed_dict={x: tt[0], keep_prob: 1.0})\n",
    "                if len(predictions):\n",
    "                    predictions = np.concatenate((predictions, p))\n",
    "                else:\n",
    "                    predictions = p\n",
    "                \n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "\n",
    "        \n",
    "        #print(predictions)\n",
    "        preds = [label_order[p] for p in predictions] \n",
    "        print(set(preds))\n",
    "        #write predictions at each epoch \n",
    "        np.save('workfile' + str(i), preds)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(\"end epoch: \" + str(i) + \" minutes run: \" + str(elapsed_time/60))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO at end, sort things by the test labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#use this \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_preds = np.load(\"workfiletry28.npy\")\n",
    "sub = pd.DataFrame()\n",
    "sub[\"id\"] = test_labels\n",
    "sub[\"person\"] = new_preds\n",
    "sub[\"id\"] = pd.to_numeric(sub[\"id\"])\n",
    "sub.sort_values(\"id\").to_csv(\"subm2-8.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:    \n",
    "    saver = tf.train.import_meta_graph('model5.meta')\n",
    "    saver.restore(sess,'/home/colegrigsby/proj3/model5.data-00000-of-00001')\n",
    "    predictions = []\n",
    "    sess.run(itertest.initializer)\n",
    "    while True:\n",
    "        try: \n",
    "            tt = sess.run(itertest.get_next())\n",
    "            p = sess.run(tf.argmax(y_conv, 1), feed_dict={x: tt[0], keep_prob: 1.0})\n",
    "            if len(predictions):\n",
    "                predictions = np.concatenate((predictions, p))\n",
    "            else:\n",
    "                predictions = p\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "\n",
    "\n",
    "    #print(predictions)\n",
    "    preds = [label_order[p] for p in predictions] \n",
    "    print(set(preds))\n",
    "    #write predictions at each epoch \n",
    "    np.save('testing', preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
